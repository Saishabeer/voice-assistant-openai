{#Auto-stop the session when the user ends: after saving with close=true (via tool-call or heuristic), call stop({ skipSave: true }).#}
<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Live AI Voice Assist (OpenAI Realtime)</title>
  <style>
    :root { --bg:#0f1115; --panel:#161a22; --text:#e6e9ef; --muted:#9aa4b2; --accent:#3b82f6; --border:#222837; }
    html, body { height:100%; }
    body { font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin:0; background:#0f1115; color:var(--text); }
    .container { max-width: 980px; margin: 32px auto; padding: 0 20px; }
    #controls { display:flex; align-items:center; gap:10px; margin-bottom:18px; }
    #controls button { padding:10px 14px; border-radius:10px; border:1px solid var(--border); background:#1a2230; color:var(--text); cursor:pointer; }
    #controls button[disabled] { opacity:.5; cursor:not-allowed; }
    #status { color: var(--muted); font-size:.95em; margin-left:6px; }
    .row { display:flex; gap:18px; align-items:stretch; }
    .col { flex:1; min-width:280px; }
    .panel { background:var(--panel); border:1px solid var(--border); border-radius:12px; padding:12px; min-height:180px; }
    .label { font-weight:600; margin-bottom:8px; color:#b6c2d0; }
    #userTranscript, #aiTranscript { white-space:pre-wrap; min-height:130px; }
    audio { width:100%; margin-top:6px; }
    .muted { color:var(--muted); }
  </style>
</head>
<body>
<div class="container">
  <h1>Live AI Voice Assist</h1>
  <div id="controls">
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <span id="status">Idle</span>
  </div>

  <div class="row">
    <div class="col">
      <div class="panel">
        <div class="label">You (live transcription)</div>
        <div id="userTranscript" class="muted">Speak after you click Start…</div>
      </div>
    </div>
    <div class="col">
      <div class="panel">
        <div class="label">Assistant (text)</div>
        <div id="aiTranscript" class="muted">The assistant will respond here.</div>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>
    </div>
  </div>
</div>

<script>
(function(){
  const startBtn = document.getElementById("startBtn");
  const stopBtn  = document.getElementById("stopBtn");
  const statusEl = document.getElementById("status");
  const userEl   = document.getElementById("userTranscript");
  const aiEl     = document.getElementById("aiTranscript");
  const aiAudio  = document.getElementById("aiAudio");

  let pc = null, micStream = null, eventsDC = null, sessionId = "", conversationId = null;
  const DEBUG_EVENTS = false;

  // Autosave & upsert state
  const AUTO_SAVE_IDLE_MS = 8000;
  const MIN_SAVE_INTERVAL_MS = 10000;
  let autosaveTimer = null, dirty = false, lastSnapshot = "", lastSaveAt = 0, saving = false, finalized = false;

  // Track function call args by call id
  const fnArgBuffers = Object.create(null);

  function setStatus(t){ statusEl.textContent = t; }
  function clearEl(el){ el.textContent=""; el.classList.remove("muted"); }
  function append(el, t){ el.textContent += t; el.scrollTop = el.scrollHeight; }
  function appendLine(el, t){ append(el, (t||"") + "\n"); }

  function markDirty(){ if (!finalized) { dirty = true; scheduleAutoSave(); } }
  function scheduleAutoSave(delayMs){
    const wait = typeof delayMs === "number" ? delayMs : AUTO_SAVE_IDLE_MS;
    if (autosaveTimer) clearTimeout(autosaveTimer);
    autosaveTimer = setTimeout(() => tryAutoSave("idle"), wait);
  }
  function currentSnapshot(){ return (userEl.textContent||"") + "\n----\n" + (aiEl.textContent||""); }

  // Heuristic end-of-conversation detection (purchase completed or user exits)
  function checkEndOfConversation() {
    if (finalized) return;
    const txt = ((userEl.textContent || "") + "\n" + (aiEl.textContent || "")).toLowerCase();
    const purchaseSignals = ["purchase completed", "payment successful", "order confirmed", "checkout complete", "transaction id", "order number", "your receipt", "booking confirmed"];
    const endIntentSignals = ["bye", "goodbye", "that’s all", "thats all", "that's all", "thanks, that's all", "no thanks", "don't want to continue", "do not want to continue", "end the conversation", "stop now", "we are done", "that's it", "thats it"];
    if (purchaseSignals.some(s => txt.includes(s)) || endIntentSignals.some(s => txt.includes(s))) {
      // Finalize row (close: true), then auto-stop.
      finalized = true;
      (async () => {
        setStatus("Finalizing…");
        await saveConversation({ autosave: true, reason: "end_detected", close: true });
        await stop({ skipSave: true });
      })();
    }
  }

  function attachEventChannel(dc){
    if (!dc) return;
    eventsDC = dc;
    eventsDC.onopen = () => setStatus("Connected.");
    eventsDC.onclose = async () => {
      setStatus("Events channel closed.");
      // Best-effort final save (do not close row here)
      await tryAutoSave("channel_closed");
    };
    eventsDC.onmessage = (ev) => {
      let evt; try { evt = JSON.parse(ev.data); } catch { return; }
      if (DEBUG_EVENTS) console.log("oai-event:", evt);
      handleRealtimeEvent(evt);
    };
  }

  function handleFunctionCallEvent(evt) {
    const call = evt?.function_call || evt?.tool_call || {};
    const id = call?.id || evt?.id || "default";
    const name = call?.name || evt?.name || "";
    if (evt.type === "response.function_call.arguments.delta" || evt.type === "response.tool_call.delta") {
      const delta = evt?.delta || evt?.arguments_delta || "";
      if (!fnArgBuffers[id]) fnArgBuffers[id] = "";
      if (typeof delta === "string") fnArgBuffers[id] += delta;
      return;
    }
    if (evt.type === "response.function_call.arguments.done" || evt.type === "response.tool_call.completed") {
      const buf = fnArgBuffers[id] || "";
      delete fnArgBuffers[id];
      let args = {};
      try {
        const s = buf.indexOf("{"), e = buf.lastIndexOf("}");
        const jsonStr = (s !== -1 && e > s) ? buf.slice(s, e+1) : buf;
        args = JSON.parse(jsonStr);
      } catch {}
      const fnName = name || evt?.name || call?.name || "";
      if (fnName === "finalize_conversation") {
        const reason = (args && typeof args.reason === "string" && args.reason) ? args.reason : "user ended";
        finalized = true;
        (async () => {
          setStatus("Finalizing…");
          await saveConversation({ autosave: true, reason, close: true });
          await stop({ skipSave: true });
        })();
      }
      return;
    }
  }

  function handleRealtimeEvent(evt){
    const t = evt?.type || "";

    // Function/tool call routing
    if (t.startsWith("response.function_call") || t.startsWith("response.tool_call")) {
      handleFunctionCallEvent(evt);
      return;
    }

    // User live transcription
    if (t.includes("transcription.delta")) {
      const text = extractText(evt);
      if (text) append(userEl, text);
      markDirty();
      return;
    }
    if (t.includes("transcription.completed")) {
      appendLine(userEl, "");
      scheduleAutoSave(3000);
      checkEndOfConversation();
      return;
    }

    // Assistant text
    if (t === "response.output_text.delta" || (t.startsWith("response.") && t.endsWith(".delta"))) {
      const text = extractText(evt);
      if (text) append(aiEl, text);
      markDirty();
      return;
    }
    if (t === "response.output_text.done" || t === "response.completed") {
      appendLine(aiEl, "");
      scheduleAutoSave(3000);
      checkEndOfConversation();
      return;
    }
  }

  function extractText(evt){
    if (!evt || typeof evt !== "object") return null;
    if (typeof evt.delta === "string") return evt.delta;
    if (evt.delta && typeof evt.delta.text === "string") return evt.delta.text;
    if (typeof evt.text === "string") return evt.text;
    if (typeof evt.transcript === "string") return evt.transcript;
    if (typeof evt.message === "string") return evt.message;
    if (evt.output_text && Array.isArray(evt.output_text)) return evt.output_text.join("");
    return null;
  }

  async function start(){
    startBtn.disabled = true; stopBtn.disabled = false;
    setStatus("Requesting microphone...");
    clearEl(userEl); clearEl(aiEl);
    if (autosaveTimer) clearTimeout(autosaveTimer);
    autosaveTimer = null; dirty = false; lastSnapshot = ""; lastSaveAt = 0; finalized = false; conversationId = null;

    try { micStream = await navigator.mediaDevices.getUserMedia({ audio: true }); }
    catch { setStatus("Microphone access denied."); startBtn.disabled=false; stopBtn.disabled=true; return; }

    setStatus("Creating session...");
    let session;
    try {
      const r = await fetch("/session/");
      if (!r.ok) throw new Error(await r.text());
      session = await r.json();
      sessionId = session?.id || "";
      if (!session?.client_secret?.value) throw new Error("Invalid session payload");
    } catch (e) {
      console.error(e);
      setStatus("Failed to create session.");
      startBtn.disabled=false; stopBtn.disabled=true;
      return;
    }

    const ephemeralKey = session.client_secret.value;
    const model = session.model || "gpt-4o-realtime-preview";

    setStatus("Starting WebRTC...");
    pc = new RTCPeerConnection({ iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }] });
    pc.onconnectionstatechange = async () => {
      const st = pc.connectionState;
      if (st === "disconnected" || st === "failed" || st === "closed") await tryAutoSave("connection_state_" + st);
    };
    pc.ondatachannel = (event) => { if (event.channel?.label === "oai-events") attachEventChannel(event.channel); };
    const proactiveDC = pc.createDataChannel("oai-events"); attachEventChannel(proactiveDC);
    pc.ontrack = (event) => { const [stream] = event.streams; aiAudio.srcObject = stream; };

    for (const track of micStream.getTracks()) pc.addTrack(track, micStream);
    pc.addTransceiver("audio", { direction: "recvonly" });

    const offer = await pc.createOffer(); await pc.setLocalDescription(offer);

    let answerSdp = "";
    try {
      const sdpResponse = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${ephemeralKey}`,
          "Content-Type": "application/sdp",
          "OpenAI-Beta": "realtime=v1",
        },
        body: offer.sdp,
      });
      if (!sdpResponse.ok) throw new Error(await sdpResponse.text());
      answerSdp = await sdpResponse.text();
    } catch (e) {
      console.error(e); setStatus("OpenAI SDP exchange failed."); await stop(); return;
    }

    await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });
    setStatus("Live. Speak to your mic.");
  }

  async function saveConversation(options = {}){
    const user_text = userEl.textContent || "";
    const ai_text = aiEl.textContent || "";
    const payload = {
      session_id: sessionId || "",
      user_text, ai_text,
      autosave: !!options.autosave,
      reason: options.reason || (options.autosave ? "autosave" : "manual"),
      close: !!options.close,
    };
    if (conversationId != null) payload.conversation_id = conversationId;

    const snap = currentSnapshot();
    if (!snap.trim()) return null;

    if (saving) return null;
    const now = Date.now();
    if (now - lastSaveAt < MIN_SAVE_INTERVAL_MS && options.autosave) return null;

    saving = true;
    try {
      const res = await fetch("/save-conversation/", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        keepalive: true,
        body: JSON.stringify(payload),
      });
      const js = await res.json().catch(()=> ({}));
      if (res.ok) {
        if (typeof js.id === "number") conversationId = js.id;
        lastSnapshot = snap; lastSaveAt = Date.now(); dirty = false;
      }
      return res.ok;
    } catch (e) {
      console.warn("Save failed:", e);
      scheduleAutoSave(4000);
      return null;
    } finally {
      saving = false;
    }
  }

  async function tryAutoSave(reason = "autosave"){
    if (!dirty) return;
    await saveConversation({ autosave: true, reason });
  }

  async function stop(options = {}){
    const skipSave = !!options.skipSave;
    stopBtn.disabled = true; startBtn.disabled = false; setStatus("Stopping...");
    // If not finalized via tool/heuristic, close on manual stop
    if (!skipSave) {
      await saveConversation({ autosave: true, reason: "manual_stop", close: !finalized });
    }
    try { if (eventsDC) eventsDC.close(); } catch {}
    try {
      if (pc) {
        pc.getSenders().forEach(s => { try { s.track && s.track.stop(); } catch {} });
        pc.getReceivers().forEach(r => { try { r.track && r.track.stop(); } catch {} });
        pc.close();
      }
    } catch {}
    if (micStream) { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
    if (autosaveTimer) { clearTimeout(autosaveTimer); autosaveTimer = null; }
    pc = null; eventsDC = null; setStatus("Idle");
  }

  startBtn.addEventListener("click", start);
  stopBtn.addEventListener("click", () => { stop(); });

  // Best-effort save on page unload; close if not already finalized
  window.addEventListener("beforeunload", () => {
    const data = {
      session_id: sessionId || "",
      user_text: userEl.textContent || "",
      ai_text: aiEl.textContent || "",
      autosave: true,
      reason: "beforeunload",
      close: !finalized,
    };
    if (conversationId != null) data.conversation_id = conversationId;
    try {
      navigator.sendBeacon && navigator.sendBeacon("/save-conversation/", new Blob([JSON.stringify(data)], { type: "application/json" }));
    } catch {}
  });
})();
</script>
</body>
</html>

