<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Live AI Voice Assist</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 30px; max-width: 800px; }
    #controls { margin-bottom: 20px; }
    #transcript { border: 1px solid #ddd; padding: 12px; min-height: 150px; white-space: pre-wrap; }
    button { padding: 8px 12px; margin-right:8px; }
    .status { color: #666; font-size: 0.9em; margin-top: 8px; }
  </style>
</head>
<body>
  <h1>Live AI Voice Assist</h1>
  <div id="controls">
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <span class="status" id="status">Idle</span>
  </div>

  <h3>Live Transcript</h3>
  <div id="transcript"></div>

<script>
(async function() {
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");
  const statusEl = document.getElementById("status");
  const transcriptEl = document.getElementById("transcript");

  let ws;
  let mediaRecorder;
  let localStream;
  let chunks = [];
  let chosenMime = 'audio/webm;codecs=opus';

  function appendTranscript(text){
    transcriptEl.textContent += (text ? (text + "\n") : "");
    transcriptEl.scrollTop = transcriptEl.scrollHeight;
  }

  async function openWS(){
    const protocol = window.location.protocol === "https:" ? "wss" : "ws";
    const url = `${protocol}://${window.location.host}/ws/audio/`;
    ws = new WebSocket(url);

    ws.onopen = () => {
      statusEl.textContent = "WebSocket connected.";
    };
    ws.onmessage = (e) => {
      try {
        const data = JSON.parse(e.data);
        if(data.type === "transcript"){
          appendTranscript(data.text);
          statusEl.textContent = "Transcription received.";
        } else if (data.type === "info") {
          // ignore
        } else if (data.type === "error") {
          appendTranscript(`[server error] ${data.message}`);
          statusEl.textContent = "Server error.";
        }
      } catch(err){
        console.error("WS message parse error", err, e.data);
      }
    };
    ws.onclose = ()=> statusEl.textContent = "WebSocket closed.";
    ws.onerror = () => statusEl.textContent = "WebSocket error";
  }

  function blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result);
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  function getBestMime() {
    if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
      return 'audio/ogg;codecs=opus';
    }
    if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
      return 'audio/webm;codecs=opus';
    }
    return '';
  }

  startBtn.onclick = async () => {
    startBtn.disabled = true;
    stopBtn.disabled = false;
    statusEl.textContent = "Requesting microphone...";
    try {
      localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } catch(err) {
      statusEl.textContent = "Microphone access denied.";
      startBtn.disabled = false;
      stopBtn.disabled = true;
      return;
    }

    await openWS();

    statusEl.textContent = "Recording...";
    chosenMime = getBestMime();
    const options = chosenMime ? { mimeType: chosenMime } : undefined;
    chunks = [];
    mediaRecorder = new MediaRecorder(localStream, options);

    mediaRecorder.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        chunks.push(event.data);
      }
    };

    mediaRecorder.onstop = async () => {
      try {
        statusEl.textContent = "Preparing audio...";
        const type = chunks[0]?.type || (chosenMime || 'audio/webm');
        const blob = new Blob(chunks, { type });
        const b64 = await blobToBase64(blob);

        statusEl.textContent = "Uploading for transcription...";
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: "final", audio_base64: b64, mime: type, language: "en" }));
        } else {
          appendTranscript("[client error] WebSocket not open.");
        }
      } catch (e) {
        appendTranscript(`[client error] ${e?.message || e}`);
      } finally {
        statusEl.textContent = "Idle";
      }
    };

    mediaRecorder.start();
  };

  stopBtn.onclick = () => {
    stopBtn.disabled = true;
    startBtn.disabled = false;
    statusEl.textContent = "Stopping...";
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
    if (localStream) {
      localStream.getTracks().forEach(t=>t.stop());
      localStream = null;
    }
  };
})();
</script>
</body>
</html>
